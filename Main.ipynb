{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba292153-7643-4a9c-97a8-9b28c76e6843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "# Configuration for the solar panel efficiency prediction pipeline\n",
    "\n",
    "data:\n",
    "  train_path: 'C:\\Users\\pc\\Downloads\\Zelestra AWS ML Ascend Challange - Copy\\train.csv'\n",
    "  test_path: 'C:\\Users\\pc\\Downloads\\Zelestra AWS ML Ascend Challange - Copy\\test.csv'\n",
    "\n",
    "output:\n",
    "  dir: 'C:\\Users\\pc\\Downloads\\Zelestra AWS ML Ascend Challange - Copy\\Submission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35bfde03-4e20-4cf3-be6e-b86647818ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/media/ayon1901/SERVER1/Zelestra/.venv/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Main script that orchestrates the solar panel efficiency prediction pipeline.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import logging\n",
    "import time\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Configure logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Load configuration from config.yaml\"\"\"\n",
    "    with open('config.yaml', 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def create_output_dir(base_dir):\n",
    "    \"\"\"Create output directory with timestamp\"\"\"\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    output_dir = os.path.join(base_dir, f'run_{timestamp}')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def add_basic_features(df):\n",
    "    \"\"\"Add basic domain-specific features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert columns to numeric\n",
    "    numeric_columns = ['humidity', 'wind_speed', 'pressure', 'temperature', \n",
    "                      'irradiance', 'module_temperature', 'cloud_coverage',\n",
    "                      'voltage', 'current', 'soiling_ratio', 'panel_age',\n",
    "                      'maintenance_count']\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Handle missing values for numeric columns first\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "    \n",
    "    # 1. Enhanced irradiance and soiling features\n",
    "    if 'irradiance' in df.columns and 'soiling_ratio' in df.columns:\n",
    "        # Effective irradiance considering soiling\n",
    "        df['effective_irradiance'] = df['irradiance'] * df['soiling_ratio']\n",
    "        # Non-linear irradiance effects\n",
    "        df['irradiance_squared'] = df['irradiance'] ** 2\n",
    "        df['irradiance_sqrt'] = np.sqrt(df['irradiance'].clip(lower=0))\n",
    "        # Soiling impact at different irradiance levels\n",
    "        df['soiling_irradiance_interaction'] = df['soiling_ratio'] * df['irradiance_sqrt']\n",
    "    \n",
    "    # 2. Enhanced aging features\n",
    "    if 'panel_age' in df.columns:\n",
    "        # Non-linear aging effects\n",
    "        df['age_squared'] = df['panel_age'] ** 2\n",
    "        df['age_sqrt'] = np.sqrt(df['panel_age'].clip(lower=0))\n",
    "        \n",
    "        if 'maintenance_count' in df.columns:\n",
    "            # Maintenance effectiveness\n",
    "            df['maintenance_frequency'] = df['maintenance_count'] / (df['panel_age'] + 1)\n",
    "            df['maintenance_effectiveness'] = df['maintenance_count'] * np.exp(-0.1 * df['panel_age'])\n",
    "            \n",
    "        if 'soiling_ratio' in df.columns:\n",
    "            # Age-related degradation\n",
    "            df['age_degradation'] = df['soiling_ratio'] * np.exp(-0.05 * df['panel_age'])\n",
    "    \n",
    "    # 3. Power quality features\n",
    "    if all(col in df.columns for col in ['voltage', 'current']):\n",
    "        df['power'] = df['voltage'] * df['current']\n",
    "        mean_voltage = df['voltage'].mean()\n",
    "        mean_current = df['current'].mean()\n",
    "        if mean_voltage != 0 and mean_current != 0:\n",
    "            df['power_quality'] = df['power'] / (mean_voltage * mean_current)\n",
    "            # Add power curve characteristics\n",
    "            df['power_factor'] = df['power'] / (df['voltage'] * df['current'])\n",
    "            df['power_efficiency'] = df['power'] / (df['irradiance'] + 1e-6)\n",
    "        else:\n",
    "            df['power_quality'] = 0\n",
    "            df['power_factor'] = 0\n",
    "            df['power_efficiency'] = 0\n",
    "    \n",
    "    # 4. Enhanced temperature features\n",
    "    if 'temperature' in df.columns:\n",
    "        # Standard temperature coefficient for solar panels (-0.4% per degree C above 25Â°C)\n",
    "        temp_coef = -0.004\n",
    "        df['temp_efficiency_factor'] = 1 + temp_coef * (df['temperature'] - 25)\n",
    "        \n",
    "        # Non-linear temperature effects\n",
    "        df['temp_squared'] = df['temperature'] ** 2\n",
    "        df['temp_stress'] = np.abs(df['temperature'] - 25)  # Deviation from optimal\n",
    "        \n",
    "        if 'module_temperature' in df.columns:\n",
    "            df['temp_difference'] = df['module_temperature'] - df['temperature']\n",
    "            df['temp_ratio'] = (df['module_temperature'] + 273.15) / (df['temperature'] + 273.15)\n",
    "            df['temp_stress_combined'] = df['temp_stress'] * np.abs(df['temp_difference'])\n",
    "    \n",
    "    # 5. Enhanced environmental features\n",
    "    weather_cols = ['humidity', 'cloud_coverage', 'wind_speed', 'pressure']\n",
    "    if all(col in df.columns for col in weather_cols):\n",
    "        # Normalize factors\n",
    "        humidity_factor = df['humidity'].astype(float) / 100.0\n",
    "        cloud_factor = df['cloud_coverage'].astype(float) / 100.0\n",
    "        max_wind = df['wind_speed'].max()\n",
    "        wind_factor = df['wind_speed'].astype(float) / max_wind if max_wind > 0 else 0\n",
    "        pressure_factor = (df['pressure'] - df['pressure'].mean()) / df['pressure'].std()\n",
    "        \n",
    "        # Combined weather impact\n",
    "        df['weather_impact'] = (\n",
    "            -0.3 * humidity_factor +  # Higher humidity reduces efficiency\n",
    "            -0.5 * cloud_factor +    # Cloud coverage has major impact\n",
    "            0.2 * wind_factor +      # Wind helps cool panels\n",
    "            0.1 * pressure_factor    # Pressure has minor impact\n",
    "        )\n",
    "        \n",
    "        # Weather stress indicators\n",
    "        df['humidity_stress'] = (humidity_factor - 0.5).abs()  # Deviation from 50% humidity\n",
    "        df['weather_stability'] = 1 - (df['weather_impact'].std() / (np.abs(df['weather_impact'].mean()) + 1e-6))\n",
    "        \n",
    "        # Cooling effect\n",
    "        if 'temp_difference' in df.columns:\n",
    "            df['cooling_effect'] = wind_factor * df['temp_difference']\n",
    "    \n",
    "    # 6. Panel health indicators\n",
    "    if 'module_temperature' in df.columns and 'temperature' in df.columns:\n",
    "        mean_diff = df['temp_difference'].mean()\n",
    "        df['panel_health'] = 1 / (1 + np.exp(df['temp_difference'] - mean_diff))\n",
    "        \n",
    "        if 'soiling_ratio' in df.columns and 'panel_age' in df.columns:\n",
    "            # Combined health score\n",
    "            df['overall_health'] = (\n",
    "                df['panel_health'] * \n",
    "                df['soiling_ratio'] * \n",
    "                np.exp(-0.03 * df['panel_age']) *  # Age degradation factor\n",
    "                (1 + df['maintenance_frequency'])   # Maintenance boost\n",
    "            )\n",
    "    \n",
    "    # 7. Time-based features\n",
    "    if 'datetime' in df.columns:\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        df['hour'] = df['datetime'].dt.hour\n",
    "        df['month'] = df['datetime'].dt.month\n",
    "        df['day_of_year'] = df['datetime'].dt.dayofyear\n",
    "        \n",
    "        # Enhanced solar position and seasonal effects\n",
    "        hour_rad = 2 * np.pi * df['hour'].astype(float) / 24\n",
    "        day_rad = 2 * np.pi * df['day_of_year'].astype(float) / 365\n",
    "        \n",
    "        df['solar_elevation'] = np.sin(hour_rad) * np.sin(day_rad)\n",
    "        df['solar_azimuth'] = np.cos(hour_rad) * np.cos(day_rad)\n",
    "        df['seasonal_factor'] = np.sin(day_rad + np.pi/6)  # Phase shift for seasonal lag\n",
    "        \n",
    "        # Time-based efficiency factors\n",
    "        if 'irradiance' in df.columns:\n",
    "            df['time_efficiency'] = df['solar_elevation'] * df['irradiance'] / (df['irradiance'].max() + 1e-6)\n",
    "    \n",
    "    # Fill any remaining missing values with 0\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def select_features(X_train, y_train, X_val, X_test, threshold=0.01, cat_features=None):\n",
    "    \"\"\"Select important features using CatBoost's feature importance\"\"\"\n",
    "    # Train a quick model to get feature importances\n",
    "    selector_model = CatBoostRegressor(\n",
    "        iterations=200,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        verbose=0\n",
    "    )\n",
    "    selector_model.fit(X_train, y_train, cat_features=cat_features, verbose=0)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importance_scores = selector_model.get_feature_importance()\n",
    "    feature_names = X_train.columns.tolist()\n",
    "    \n",
    "    # Create importance dictionary\n",
    "    importance_dict = dict(zip(feature_names, importance_scores))\n",
    "    \n",
    "    # Select features above threshold\n",
    "    selected_features = [f for f, imp in importance_dict.items() if imp > threshold]\n",
    "    logger.info(f\"Selected {len(selected_features)} features out of {len(feature_names)}\")\n",
    "    \n",
    "    # Log top 10 features\n",
    "    top_features = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    logger.info(\"Top 10 features:\")\n",
    "    for feature, importance in top_features:\n",
    "        logger.info(f\"  - {feature}: {importance:.6f}\")\n",
    "    \n",
    "    return X_train[selected_features], X_val[selected_features], X_test[selected_features], selected_features\n",
    "\n",
    "def add_advanced_features(df):\n",
    "    \"\"\"Add advanced feature engineering to capture non-linear relationships and domain-specific insights\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Polynomial features for key numerical columns\n",
    "    key_numerical_cols = ['irradiance', 'temperature', 'module_temperature', 'voltage', 'current', 'soiling_ratio']\n",
    "    for col in key_numerical_cols:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_squared'] = df[col] ** 2\n",
    "            df[f'{col}_cubed'] = df[col] ** 3\n",
    "            df[f'{col}_sqrt'] = np.sqrt(df[col].clip(lower=0))\n",
    "    \n",
    "    # Interaction terms between key features\n",
    "    if 'irradiance' in df.columns and 'temperature' in df.columns:\n",
    "        df['irradiance_temp_interaction'] = df['irradiance'] * df['temperature']\n",
    "    if 'voltage' in df.columns and 'current' in df.columns:\n",
    "        df['voltage_current_interaction'] = df['voltage'] * df['current']\n",
    "    if 'irradiance' in df.columns and 'soiling_ratio' in df.columns:\n",
    "        df['irradiance_soiling_interaction'] = df['irradiance'] * df['soiling_ratio']\n",
    "    if 'temperature' in df.columns and 'module_temperature' in df.columns:\n",
    "        df['temp_module_diff_squared'] = (df['temperature'] - df['module_temperature']) ** 2\n",
    "    \n",
    "    # Log transformations for skewed features\n",
    "    for col in key_numerical_cols:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_log'] = np.log1p(df[col].clip(lower=0))\n",
    "    \n",
    "    # Domain-specific derived columns for solar panel efficiency\n",
    "    if 'voltage' in df.columns and 'current' in df.columns:\n",
    "        df['power_estimate'] = df['voltage'] * df['current']\n",
    "    if 'power_estimate' in df.columns and 'irradiance' in df.columns:\n",
    "        df['efficiency_estimate'] = df['power_estimate'] / (df['irradiance'] + 0.0001)  # Avoid division by zero\n",
    "    if 'temperature' in df.columns and 'module_temperature' in df.columns:\n",
    "        df['temp_module_ratio'] = df['module_temperature'] / (df['temperature'] + 0.0001)  # Avoid division by zero\n",
    "    if 'irradiance' in df.columns:\n",
    "        df['irradiance_normalized'] = df['irradiance'] / (df['irradiance'].max() + 0.0001)  # Normalize irradiance\n",
    "    \n",
    "    # Additional interaction terms for nuanced effects\n",
    "    if 'soiling_ratio' in df.columns and 'temperature' in df.columns:\n",
    "        df['soiling_temp_interaction'] = df['soiling_ratio'] * df['temperature']\n",
    "    if 'voltage' in df.columns and 'temperature' in df.columns:\n",
    "        df['voltage_temp_interaction'] = df['voltage'] * df['temperature']\n",
    "    \n",
    "    # Fill any NaN values created by transformations, only for numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_time_series_features(df):\n",
    "    \"\"\"Add time-series features like lags and rolling windows.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'datetime' not in df.columns or 'string_id' not in df.columns:\n",
    "        logger.warning(\"Datetime or string_id not in columns, skipping time-series features.\")\n",
    "        return df\n",
    "    \n",
    "    logger.info(\"Adding time-series features...\")\n",
    "    \n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values(by=['string_id', 'datetime'])\n",
    "    \n",
    "    # Features to apply time-series logic on\n",
    "    ts_features = ['irradiance', 'temperature', 'module_temperature', 'cloud_coverage', 'wind_speed', 'humidity', 'pressure']\n",
    "    \n",
    "    # Lag periods and rolling window sizes\n",
    "    lags = [1, 2]\n",
    "    window_sizes = [3, 6]\n",
    "    \n",
    "    grouped = df.groupby('string_id')\n",
    "    \n",
    "    for col in ts_features:\n",
    "        if col in df.columns:\n",
    "            # Lag features\n",
    "            for lag in lags:\n",
    "                df[f'{col}_lag_{lag}'] = grouped[col].shift(lag)\n",
    "            \n",
    "            # Rolling window features\n",
    "            for window in window_sizes:\n",
    "                df[f'{col}_roll_mean_{window}'] = grouped[col].rolling(window=window, min_periods=1).mean()\n",
    "                df[f'{col}_roll_std_{window}'] = grouped[col].rolling(window=window, min_periods=1).std()\n",
    "\n",
    "    # Backfill to handle NaNs at the start of each group\n",
    "    df = df.bfill()\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    logger.info(\"Finished adding time-series features.\")\n",
    "    return df\n",
    "\n",
    "def run_pipeline(config):\n",
    "    \"\"\"Run the pipeline leveraging key categorical features for improved performance\"\"\"\n",
    "    start_time = time.time()\n",
    "    logger.info(\"Starting optimized CatBoost modeling pipeline with Categorical Features\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_path = create_output_dir(config['output']['dir'])\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    logger.info(\"Loading and preprocessing data...\")\n",
    "    train_df = pd.read_csv(config['data']['train_path'])\n",
    "    test_df = pd.read_csv(config['data']['test_path'])\n",
    "    \n",
    "    # Handle outliers in training data (as in best run)\n",
    "    logger.info(\"Handling outliers in training data...\")\n",
    "    train_df, outlier_info = handle_outliers(train_df, target_column='efficiency', z_threshold=3)\n",
    "    logger.info(f\"Outlier handling summary: {outlier_info}\")\n",
    "    \n",
    "    # Basic feature engineering\n",
    "    train_df = add_basic_features(train_df)\n",
    "    test_df = add_basic_features(test_df)\n",
    "    \n",
    "    # Advanced feature engineering\n",
    "    logger.info(\"Performing advanced feature engineering...\")\n",
    "    train_df = add_advanced_features(train_df)\n",
    "    test_df = add_advanced_features(test_df)\n",
    "\n",
    "    # Define and process categorical features\n",
    "    cat_features = ['string_id', 'error_code', 'installation_type']\n",
    "    for col in cat_features:\n",
    "        if col in train_df.columns:\n",
    "            train_df[col] = train_df[col].astype(str).fillna('NA')\n",
    "        if col in test_df.columns:\n",
    "            test_df[col] = test_df[col].astype(str).fillna('NA')\n",
    "\n",
    "    # Prepare features and target\n",
    "    y_train = train_df['efficiency']\n",
    "    \n",
    "    # Align columns before splitting\n",
    "    train_cols = [col for col in train_df.columns if col not in ['id', 'efficiency']]\n",
    "    test_cols = [col for col in test_df.columns if col not in ['id']]\n",
    "    shared_cols = list(set(train_cols) & set(test_cols))\n",
    "    \n",
    "    X = train_df[shared_cols]\n",
    "    X_test = test_df[shared_cols]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, y_train_split, y_val = train_test_split(\n",
    "        X, y_train, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Get final list of categorical features present in the training data\n",
    "    final_cat_features = [col for col in cat_features if col in X_train.columns]\n",
    "    \n",
    "    # Feature selection\n",
    "    logger.info(\"Performing feature selection...\")\n",
    "    X_train_selected, X_val_selected, X_test_selected, selected_features = select_features(X_train, y_train_split, X_val, X_test, cat_features=final_cat_features)\n",
    "    logger.info(f\"Selected features: {selected_features}\")\n",
    "\n",
    "    # Update cat features list to only include selected ones\n",
    "    final_cat_features_selected = [f for f in final_cat_features if f in selected_features]\n",
    "    \n",
    "    # Refined hyperparameter tuning for a single CatBoost model\n",
    "    logger.info(\"Tuning CatBoost model with MAE loss and categorical features...\")\n",
    "    param_grid = [\n",
    "        # Original candidates\n",
    "        {'iterations': 5000, 'learning_rate': 0.01, 'depth': 8, 'l2_leaf_reg': 3, 'subsample': 0.8},\n",
    "        {'iterations': 6000, 'learning_rate': 0.008, 'depth': 9, 'l2_leaf_reg': 5, 'subsample': 0.75},\n",
    "        {'iterations': 7000, 'learning_rate': 0.005, 'depth': 10, 'l2_leaf_reg': 7, 'subsample': 0.7},\n",
    "        # More aggressive learning\n",
    "        {'iterations': 4000, 'learning_rate': 0.02, 'depth': 7, 'l2_leaf_reg': 4, 'subsample': 0.85},\n",
    "        # Deeper model with smaller learning rate\n",
    "        {'iterations': 8000, 'learning_rate': 0.004, 'depth': 11, 'l2_leaf_reg': 6, 'subsample': 0.7},\n",
    "        # Different subsample and regularization\n",
    "        {'iterations': 5500, 'learning_rate': 0.015, 'depth': 8, 'l2_leaf_reg': 8, 'subsample': 0.9}\n",
    "    ]\n",
    "    best_params, best_score = tune_catboost_model(X_train_selected, y_train_split, X_val_selected, y_val, param_grid=param_grid, cat_features=final_cat_features_selected)\n",
    "    logger.info(f\"Best parameters for CatBoost: {best_params}\")\n",
    "    logger.info(f\"Best validation MAE for CatBoost: {best_score:.6f}\")\n",
    "    \n",
    "    # Train the final model with best parameters\n",
    "    logger.info(\"Training final CatBoost model with best parameters...\")\n",
    "    final_model = CatBoostRegressor(loss_function='MAE', **best_params)\n",
    "    final_model.fit(X_train_selected, y_train_split, eval_set=(X_val_selected, y_val), use_best_model=True, verbose=0, cat_features=final_cat_features_selected)\n",
    "    \n",
    "    # Final predictions\n",
    "    final_val_pred = final_model.predict(X_val_selected)\n",
    "    final_test_pred = final_model.predict(X_test_selected)\n",
    "    \n",
    "    # Post-processing: Adjust predictions based on validation set bias\n",
    "    logger.info(\"Applying linear residual correction...\")\n",
    "    val_residuals = y_val - final_val_pred\n",
    "    residual_model = LinearRegression()\n",
    "    residual_model.fit(final_val_pred.reshape(-1, 1), val_residuals)\n",
    "    test_residual_pred = residual_model.predict(final_test_pred.reshape(-1, 1))\n",
    "    final_test_pred_adjusted = final_test_pred + test_residual_pred\n",
    "    final_test_pred_adjusted = np.clip(final_test_pred_adjusted, 0, 1)\n",
    "    logger.info(\"Post-processing applied: added linear residuals and clipped predictions\")\n",
    "    \n",
    "    # Calculate validation metrics (pre-adjustment for reference)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, final_val_pred))\n",
    "    val_mae = mean_absolute_error(y_val, final_val_pred)\n",
    "    val_r2 = r2_score(y_val, final_val_pred)\n",
    "    \n",
    "    logger.info(f\"Validation RMSE (pre-adjustment): {val_rmse:.6f}\")\n",
    "    logger.info(f\"Validation MAE (pre-adjustment): {val_mae:.6f}\")\n",
    "    logger.info(f\"Validation R2 (pre-adjustment): {val_r2:.6f}\")\n",
    "    \n",
    "    # Save predictions (adjusted)\n",
    "    test_df['efficiency'] = final_test_pred_adjusted\n",
    "    test_df[['id', 'efficiency']].to_csv(\n",
    "        os.path.join(output_path, 'predictions_adjusted_cat_features.csv'),\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    # Save model and analysis\n",
    "    logger.info(\"Saving model and analysis...\")\n",
    "    final_model.save_model(os.path.join(output_path, 'catboost_final_cat_features.cbm'))\n",
    "    save_feature_importance(final_model, selected_features, output_path, 'catboost_final_cat_features')\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    logger.info(f\"Total execution time: {execution_time:.2f} seconds\")\n",
    "    \n",
    "    return final_test_pred_adjusted\n",
    "\n",
    "def tune_catboost_model(X_train, y_train, X_val, y_val, param_grid=None, cat_features=None):\n",
    "    \"\"\"Enhanced hyperparameter tuning for CatBoost model with MAE loss\"\"\"\n",
    "    if param_grid is None:\n",
    "        param_grid = [\n",
    "            # Original candidates\n",
    "            {'iterations': 5000, 'learning_rate': 0.01, 'depth': 8, 'l2_leaf_reg': 3, 'subsample': 0.8},\n",
    "            {'iterations': 6000, 'learning_rate': 0.008, 'depth': 9, 'l2_leaf_reg': 5, 'subsample': 0.75},\n",
    "            {'iterations': 7000, 'learning_rate': 0.005, 'depth': 10, 'l2_leaf_reg': 7, 'subsample': 0.7},\n",
    "            # More aggressive learning\n",
    "            {'iterations': 4000, 'learning_rate': 0.02, 'depth': 7, 'l2_leaf_reg': 4, 'subsample': 0.85},\n",
    "            # Deeper model with smaller learning rate\n",
    "            {'iterations': 8000, 'learning_rate': 0.004, 'depth': 11, 'l2_leaf_reg': 6, 'subsample': 0.7},\n",
    "            # Different subsample and regularization\n",
    "            {'iterations': 5500, 'learning_rate': 0.015, 'depth': 8, 'l2_leaf_reg': 8, 'subsample': 0.9}\n",
    "        ]\n",
    "    \n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    \n",
    "    for params in param_grid:\n",
    "        logger.info(f\"Trying parameters: {params}\")\n",
    "        model = CatBoostRegressor(\n",
    "            loss_function='MAE',\n",
    "            eval_metric='MAE',\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=0,\n",
    "            random_seed=42,\n",
    "            **params\n",
    "        )\n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True, cat_features=cat_features)\n",
    "        val_pred = model.predict(X_val)\n",
    "        score = mean_absolute_error(y_val, val_pred)\n",
    "        logger.info(f\"Validation MAE for this set: {score:.6f}\")\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = model.get_params()\n",
    "    \n",
    "    # Remove parameters that are not for the constructor\n",
    "    best_params.pop('loss_function', None)\n",
    "    best_params.pop('eval_metric', None)\n",
    "    best_params.pop('early_stopping_rounds', None)\n",
    "    best_params.pop('verbose', None)\n",
    "    best_params.pop('cat_features', None)\n",
    "\n",
    "    return best_params, best_score\n",
    "\n",
    "def save_feature_importance(model, feature_names, output_path, model_name):\n",
    "    \"\"\"Save feature importance plot and CSV\"\"\"\n",
    "    importance = model.get_feature_importance()\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Save to CSV\n",
    "    importance_df.to_csv(\n",
    "        os.path.join(output_path, f'{model_name}_feature_importance.csv'),\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    # Create and save plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(importance_df)), importance_df['Importance'])\n",
    "    plt.xticks(range(len(importance_df)), importance_df['Feature'], rotation=90)\n",
    "    plt.title(f'Feature Importance - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_path, f'{model_name}_feature_importance.png'))\n",
    "    plt.close()\n",
    "\n",
    "def handle_outliers(df, target_column, z_threshold=3):\n",
    "    \"\"\"Detect and cap outliers in the target column using Z-score method\"\"\"\n",
    "    df = df.copy()\n",
    "    initial_rows = len(df)\n",
    "    \n",
    "    # Calculate Z-scores for the target column\n",
    "    z_scores = np.abs((df[target_column] - df[target_column].mean()) / df[target_column].std())\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers = df[z_scores > z_threshold]\n",
    "    num_outliers = len(outliers)\n",
    "    \n",
    "    # Cap outliers instead of removing to maintain data size\n",
    "    upper_limit = df[target_column].mean() + z_threshold * df[target_column].std()\n",
    "    lower_limit = df[target_column].mean() - z_threshold * df[target_column].std()\n",
    "    df[target_column] = df[target_column].clip(lower=lower_limit, upper=upper_limit)\n",
    "    \n",
    "    outlier_info = {\n",
    "        'initial_rows': initial_rows,\n",
    "        'num_outliers_detected': num_outliers,\n",
    "        'percentage_outliers': (num_outliers / initial_rows) * 100 if initial_rows > 0 else 0,\n",
    "        'upper_limit_applied': upper_limit,\n",
    "        'lower_limit_applied': lower_limit\n",
    "    }\n",
    "    \n",
    "    return df, outlier_info\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # Load configuration\n",
    "        config = load_config()\n",
    "        logger.info(\"Configuration loaded successfully\")\n",
    "        \n",
    "        # Run the pipeline\n",
    "        predictions = run_pipeline(config)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main: {str(e)}\")\n",
    "        raise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317ff81-cf01-4382-8a1b-7bf824377b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
